{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68e68e5-3787-42c8-ae4b-ebeb3b9367de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]],\n",
       "\n",
       "        [[13, 14],\n",
       "         [15, 16]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.arange(1, 17)  # a's shape is (16,)\n",
    " \n",
    "a.view(-1,2,2) # output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f7420-7404-4e67-8531-7d280eb56592",
   "metadata": {},
   "outputs": [],
   "source": [
    "[    1,   474,   763,   304,  1083, 27224, 17774, 29889,    13, 29875,\n",
    "          763,   304,   748, 29826, 29889,    13, 29875,   763,   304, 15049,\n",
    "          263, 12580, 29889,    13,  1357, 25448,  8753, 22394,   338, 12713,\n",
    "         4657,   264, 29889,    13,  2918,  1919,   920,   526,   366,  2599,\n",
    "         1577,   474, 29915, 29885,  2805,  7960,   304,   437,   777,   923,\n",
    "          300,   801,   521,  5832,   304,  7952,   297,  8267,   869,    13,\n",
    "         6293,  1818,   367,  1407,  5172,   869, 29826,   338,   697,   310,\n",
    "          590, 25448,   298, 20838,   583,   869,    13, 29875,   626,  1738,\n",
    "          363,   590,   298,   711,  1609,   474,   763,   304,   437,   508,\n",
    "         1076,   470,   777,   377,   986,  1847,   869, \n",
    "\n",
    ".\n",
    ".[    0,     0,   474,   763,   304,  1083, 27224, 17774, 29889,     0,\n",
    "           474,   763,   304,   748, 29826, 29889,     0,   474,   763,   304,\n",
    "         15049,   263, 12580, 29889,     0,   590, 25448,  8753, 22394,   338,\n",
    "         12713,  4657,   264, 29889,     0,     0,  7251,  1919,   920,   526,\n",
    "           366,  2599,  1577,   474, 29915, 29885,  2805,  7960,   304,   437,\n",
    "           777,   923,   300,   801,   521,  5832,   304,  7952,   297,  8267,\n",
    "           869,     2,     0,   366,  1818,   367,  1407,  5172,   869, 29826,\n",
    "           338,   697,   310,   590, 25448,   298, 20838,   583,   869,     2,\n",
    "             0,   474,   626,  1738,   363,   590,   298,   711,  1609,   474,\n",
    "           763,   304,   437,   508,  1076,   470,   777,   377,   986,  1847,\n",
    "           869,     2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215d430d-5474-4acc-bd7b-4ea69809dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import LlamaForCausalLM\n",
    "pad_id = 0\n",
    "item_mine = [[2, 2, 939, 1166, 10328, 2799, 10, 76, 4, 939, 437, 10, 16391, 1457, 25, 127, 200, 633, 4, 939, 129, 3529, 36930, 4, 939, 21, 1179, 11, 10, 881, 4095, 6028, 4, 2, 20760, 99, 32, 608, 452, 17487, 2], \n",
    "             [2, 2, 939, 1166, 10328, 2799, 10, 76, 4, 939, 437, 10, 16391, 1457, 25, 127, 200, 633, 4, 939, 129, 3529, 36930, 4, 939, 21, 1179, 11, 10, 881, 4095, 6028, 4, 2, 20760, 99, 32, 608, 452, 17487, 2]]\n",
    "             \n",
    "item = [[50267, 50268, 939, 657, 2982, 2596, 1245, 8, 14926, 5282, 18292, 4, 2, 939, 657, 7, 1930, 86, 19, 127, 284, 4, 2, 939, 437, 10, 1928, 2996, 9008, 4, 2, 939, 1656, 130, 1788, 358, 183, 4, 2], \n",
    "        [50267, 50268, 939, 657, 2982, 2596, 1245, 8, 14926, 5282, 18292, 4, 2, 939, 657, 7, 1930, 86, 19, 127, 284, 4, 2, 939, 437, 10, 1928, 2996, 9008, 4, 2, 939, 1656, 130, 1788, 358, 183, 4, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97054cdf-4e48-44b9-a96a-de0be0a65cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_mine = pad_sequence([torch.from_numpy(np.array(x)) for x in item_mine],\n",
    "                                  batch_first=True, padding_value=pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5441c520-ed41-4fd0-bc02-0ccee6dcf73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"/checkpoint/llama_7B/\", padding_side=\"right\", use_fast=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./checkpoint/llama_7B\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "#model = LlamaForCausalLM.from_pretrained(\"./checkpoint/llama_7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7342c4ef-0678-473f-99a8-6add42e3ca76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token = '<\\s>'\n",
    "tokenizer.bos_token = '<s>'\n",
    "special_tokens_dict = {\"sep_token\": \"<\\sep>\", \"pad_token\": \"<\\pad>\"}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "tokenizer.add_tokens(['<query>', '<response>', '<latent>', '<persona>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "160716f5-a72d-4b5e-8229-a42edaa2aea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 32001 32000\n",
      "<s> <\\s> <\\pad> <\\sep>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id, tokenizer.sep_token_id)\n",
    "print(tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token, tokenizer.sep_token)\n",
    "print(tokenizer.convert_tokens_to_ids(['<query>', '<response>', '<latent>', '<persona>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ab996e3-21a2-465c-bc88-1d0c56694670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76237327-dfb1-4581-a0b0-16b799c2f1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.sep_token='<\\s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fde8c748-f29b-404d-8946-3acac874057d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token = '<\\s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4ca2868-ec20-4a1e-b990-e6b5825a2afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\\s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06b11c36-a555-46ae-a0b9-6ad1ac34a774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,   529, 29905, 29879, 29958]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "prompt = '<\\s>'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bed0c49-198c-44b3-87a7-f614f5802eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 18637, 29892,   526,   366, 19861, 29973,  1815,   366,  5193,\n",
      "           304,   592, 29973,    13, 29902, 29915, 29885,   451,  1854,   565,\n",
      "           366, 29915,   276, 19861, 29892,   541,   306, 29915, 29885,  2675]])\n"
     ]
    }
   ],
   "source": [
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "print(generate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7b6fbaf7-3abb-4e92-9128-ceba6c68a3be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27f8f46e-c7d7-4c94-9735-2208535aaf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <\\\\s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a251c-7f0e-475e-ac87-ceedfda55725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenizer.decode(['hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86786ed5-0d7f-42d0-b22d-ef94df35efa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5bd7c6b-0787-498c-926d-295339a7603b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = {v : k for k, v in a.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57b15bd0-bdfa-46bf-8cca-d57ddb3da06d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0x2F>\n"
     ]
    }
   ],
   "source": [
    "print(a[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a350a9aa-cff4-4ff6-8777-689d002f90c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d70d1b5dff497587b13a0ba61ed2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1535b8e45c7c4cbb93dc86f0ae883cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04767022074605ae2dca1fad4cc57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001ed30c17ce46a4ad4d63f7dd112eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2DoubleHeadsModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['multiple_choice_head.summary.bias', 'multiple_choice_head.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2530fa8e590f4951853b8d64dd025823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 13])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4, 13, 50257])\n",
      "tensor([[4.9233, 4.9585, 4.9521, 4.9414]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2DoubleHeadsModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2DoubleHeadsModel.from_pretrained('gpt2')\n",
    "\n",
    "choices = [ \"Bob likes candy ; what does Bob like ?  Bag <|endoftext|>\",\n",
    "                   \"Bob likes candy ; what does Bob like ?  Burger <|endoftext|>\",\n",
    "                   \"Bob likes candy ; what does Bob like ?  Candy <|endoftext|>\",\n",
    "                  \"Bob likes candy ; what does Bob like ?  Apple <|endoftext|>\"]\n",
    "\n",
    "encoded_choices = [tokenizer.encode(s) for s in choices]\n",
    "\n",
    "eos_token_location = [tokens.index(tokenizer.eos_token_id) for tokens in encoded_choices]\n",
    "input_ids = torch.tensor(encoded_choices).unsqueeze(0) \n",
    "mc_token_ids = torch.tensor([eos_token_location]) \n",
    "print(input_ids.shape)\n",
    "print(mc_token_ids.shape)\n",
    "outputs = model(input_ids, mc_token_ids=mc_token_ids)\n",
    "lm_prediction_scores, mc_prediction_scores = outputs[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33719677-a29c-4fd4-866d-02038c334065",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 13, 50257])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "print(lm_prediction_scores.shape)\n",
    "print(mc_prediction_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92dfcc11-a847-45dd-8eee-e7e8c59e2a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m total_step_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_step_num):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_curve\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_curve\u001b[39m\u001b[38;5;124m'\u001b[39m: math\u001b[38;5;241m.\u001b[39mlog(step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)},step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[1;32m      6\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "import wandb, random\n",
    "total_step_num = 1000\n",
    "for step in range(total_step_num):\n",
    "    wandb.log({'random_curve':step/100+random.random()},step=step)\n",
    "    wandb.log({'log_curve': math.log(step+1)},step=step)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8a4f1-2750-472d-9f5a-f455d1486a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e048369-20c7-4126-85f2-fc8f9f9eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Launch 5 simulated experiments\n",
    "total_runs = 5\n",
    "for run in range(total_runs):\n",
    "  # 🐝 1️⃣ Start a new run to track this script\n",
    "  wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"wandbexample1\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"experiment_{run}\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"CIFAR-100\",\n",
    "      \"epochs\": 10,\n",
    "      })\n",
    "  \n",
    "  # This simple block simulates a training loop logging metrics\n",
    "  epochs = 10\n",
    "  offset = random.random() / 5\n",
    "  for epoch in range(2, epochs):\n",
    "      acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "      loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "      \n",
    "      # 🐝 2️⃣ Log metrics from your script to W&B\n",
    "      wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "      \n",
    "  # Mark the run as finished\n",
    "  wandb.finish()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
