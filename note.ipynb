{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c10c8-88ee-4848-a623-6517f506e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_sft.py \\\n",
    "    --pretrain \"./checkpoint/llama_7B\" \\\n",
    "    --model 'llama' \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --log_interval 10 \\\n",
    "    --save_path \"./checkpoint_mine/step1/epoch1\" \\\n",
    "    --dataset 'PersonaChat' \\\n",
    "    --batch_size 2 \\\n",
    "    --accumulation_steps 8 \\\n",
    "    --lr 2e-5 \\\n",
    "    --max_epochs 1 \\\n",
    "    --max_datasets_size 1024 \\\n",
    "    --batch_size 2 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c3781-4e96-47fc-b749-1844b305e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_reward_model.py \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --model 'bloom' \\\n",
    "    --pretrain 'bigscience/bloom-560m' \\\n",
    "    --dataset 'PersonaChat' \\\n",
    "    --save_path './checkpoint_mine/step2/epoch1/rmstatic.pt' \\\n",
    "    --max_epochs 1 \\\n",
    "    --batch_size 8 \\\n",
    "    --loss_fn 'log_exp' \\\n",
    "    --max_datasets_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b75b1-2703-48b8-9836-68e2e292b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_prompts.py \\\n",
    "    --prompt_dataset 'datasets/seed_prompts_en.jsonl' \\\n",
    "    --pretrain_dataset 'colossalai_gemini' \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --model 'llama' \\\n",
    "    --pretrain './checkpoint_mine/step1/epoch1' \\\n",
    "    --rm_model 'llama' \\\n",
    "    --rm_path './checkpoint_mine/step2/epoch1/rmstatic.pt' \\\n",
    "    --save_path './checkpoint_mine/step3/epoch1' \\\n",
    "    --max_epochs 1 \\\n",
    "    --train_batch_size 1 \\\n",
    "    --ptx_batch_size 1 \\\n",
    "    --lora_rank 16 \\\n",
    "    --max_input_len 96 \\\n",
    "    --max_seq_len 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e19525-15c4-4e10-aa29-7673f76e355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/hpcaitech/ColossalAI/issues/3192\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 266, in <module>\n",
    "    main(args)\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 79, in main\n",
    "    reward_model.load_state_dict(state_dict)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1671, in load_state_dict\n",
    "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
    "RuntimeError: Error(s) in loading state_dict for LlamaRM:\n",
    "        Unexpected key(s) in state_dict: \"model.layers.0.self_attn.q_proj.lora_A\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc557a0-88b4-4121-9b33-ac94651d5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "I have the same problems.\n",
    "I add the `strict=False` to `reward_model.load_state_dict(state_dict)` and `critic.load_state_dict(state_dict)` can solve the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87e017-1d4c-4509-84e3-df086d896713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = data.TensorDataset(torch.randn(10, 3), torch.randn(10, 1))\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    print(f\"Batch {i}:\\n{x_batch}\\n{y_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903129f-b144-40d0-930b-904d46ef3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path: str,\n",
    "                 tokenizer: transformers.PreTrainedTokenizer,\n",
    "                 max_datasets_size: int = None,\n",
    "                 max_length: int = 96):\n",
    "        super(PromptDataset, self).__init__()\n",
    "        self.keyed_prompt = defaultdict(list)\n",
    "        logger.info(\"Loading data...\")\n",
    "        list_data_dict = jload(data_path)\n",
    "        logger.info(f\"Loaded {len(list_data_dict)} examples.\")\n",
    "\n",
    "        if max_datasets_size is not None:\n",
    "            logger.info(f\"Limiting dataset to {max_datasets_size} examples.\")\n",
    "            list_data_dict = list_data_dict[:max_datasets_size]\n",
    "\n",
    "        for data_dict in list_data_dict:\n",
    "            token = tokenizer(data_dict[\"instruction\"],\n",
    "                              return_tensors='pt',\n",
    "                              max_length=max_length,\n",
    "                              padding='max_length',\n",
    "                              truncation=True)\n",
    "            for k, tensor in token.items():\n",
    "                self.keyed_prompt[k].extend(tensor.to(torch.cuda.current_device()).unbind())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keyed_prompt[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return {k: v[i] for k, v in self.keyed_prompt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a0bf8-62f6-4fb2-a87a-542fa34aadaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataprocess import create_data\n",
    "inputs = []\n",
    "outputs = []\n",
    "persona, query, response, _ = create_data(\"./datasets/convai/train_self_original.txt\")\n",
    "print(query[0][:10])\n",
    "print(response[0][:10])\n",
    "for i in range(len(persona)):\n",
    "    dialogue = []\n",
    "    dialogue.append(query[i][0])\n",
    "    inputs.append(\"\\n\".join(persona[i]+[query[i][0]]))\n",
    "    outputs.append(response[i][0])\n",
    "    \n",
    "    for j in range(len(query[i])-1):\n",
    "        dialogue.append(response[i][j])\n",
    "        dialogue.append(query[i][j+1])\n",
    "        inputs.append(\"\\n\".join(persona[i] + dialogue))\n",
    "        outputs.append(response[i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae4a2c-6ca5-4380-961f-08c70a1b13f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for i in itertools.count(10,2):\n",
    "    print(i)\n",
    "    if i>20: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a6312-8853-44a3-9e34-68b08f28098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocess import create_data\n",
    "def PersonaPromptDataset(data_file, max_datasets_size):\n",
    "    dataset_chosen = []\n",
    "    dataset_rejected = []\n",
    "\n",
    "    persona, query, response, cand = create_data(data_file, max_datasets_size)\n",
    "    for i in range(len(persona)):\n",
    "        for j in range(len(persona[i])):\n",
    "            dataset_chosen.append(\"\\n\".join(persona[i][:j] + \n",
    "                                            list(itertools.chain.from_iterable(zip(query[i][:j],response[i][:j])))) + \"\\n\")\n",
    "            dataset_rejected.append(\"\\n\".join(persona[i][:j] + \n",
    "                                            list(itertools.chain.from_iterable(zip(query[i][:j],cand[i][:j][0])))) + \"\\n\")\n",
    "\n",
    "    return dataset_chosen, dataset_rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea92cecd-e002-4ff7-a192-539b9d6d2a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000 1000\n",
      "./datasets/convai/valid_self_original.txt has 1000 dialog and 7801 query\n"
     ]
    }
   ],
   "source": [
    "from dataprocess import HhRlhfDataset, PersonaPromptDataLoader, create_data, PersonaPromptDataset\n",
    "dataset_chosen, dataset_rejected = PersonaPromptDataset(\"./datasets/convai/valid_self_original.txt\", 999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354ed381-7601-431e-afeb-b819c2389183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m[i])\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(inputs[i])\n",
    "    print(\"-\"*25)\n",
    "    print(outputs[i])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628f86e-1f60-49d6-b56a-e8879b732b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3c15b-963f-4c3d-bc16-6d4b4ee5ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def create_data(data_file):\n",
    "    with open(data_file, \"r\", encoding=\"utf8\") as f:\n",
    "        persona =[]\n",
    "        query = []\n",
    "        response = []\n",
    "        cand = []\n",
    "        is_persona = False\n",
    "        tmp_persona = []\n",
    "        tmp_query = []\n",
    "        tmp_response = []\n",
    "        tmp_cand = []\n",
    "        first = True\n",
    "        cnt = 0\n",
    "        sum_u = 0\n",
    "        for line in f:\n",
    "            cnt += 1\n",
    "            line = line.strip()\n",
    "            if \"your persona: \" in line:\n",
    "                if not is_persona and not first:\n",
    "                    query.append(tmp_query)\n",
    "                    response.append(tmp_response)\n",
    "                    cand.append(tmp_cand)\n",
    "                    sum_u += len(tmp_query)\n",
    "                    tmp_query = []\n",
    "                    tmp_response = []\n",
    "                    tmp_cand = []\n",
    "                first = False\n",
    "                is_persona = True\n",
    "                line = line.split(\": \", maxsplit=1)[1]\n",
    "                tmp_persona.append(line)\n",
    "            else:\n",
    "                if is_persona:\n",
    "                    persona.append(tmp_persona)\n",
    "                    is_persona = False\n",
    "                    tmp_persona = []\n",
    "                line = line[line.find(\" \")+1:]\n",
    "                tmp_query.append(line.split(\"\\t\")[0])\n",
    "                tmp_response.append(line.split(\"\\t\")[1])\n",
    "                tmp_cand.append(line.split(\"\\t\")[3].split(\"|\"))\n",
    "        query.append(tmp_query)\n",
    "        response.append(tmp_response)\n",
    "        cand.append(tmp_cand)\n",
    "        sum_u += len(tmp_query)\n",
    "        assert len(query) == len(response) == len(persona) == len(cand)\n",
    "\n",
    "    print(\"{} has {} dialog and {} query\".format(data_file, len(query), sum_u))\n",
    "\n",
    "    return persona, query, response, cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb5b8a-111b-4c98-a011-e94d58bca8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_chosen = []\n",
    "train_dataset_rejected = []\n",
    "eval_dataset_chosen = []\n",
    "eval_dataset_rejected = []\n",
    "\n",
    "persona, query, response, cand = create_data(f\"./datasets/convai/valid_self_original.txt\")\n",
    "print(persona[:2])\n",
    "print()\n",
    "print(query[:2])\n",
    "print()\n",
    "print(cand[:2])\n",
    "\n",
    "for i in range(len(persona)):\n",
    "    for j in range(len(cand[i])):\n",
    "        eval_dataset_chosen.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],response[i])))) + \"\\n\")\n",
    "        eval_dataset_rejected.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],cand[i][j])))) + \"\\n\")\n",
    "train_dataset_chosen = []\n",
    "train_dataset_rejected = []\n",
    "eval_dataset_chosen = []\n",
    "eval_dataset_rejected = []\n",
    "\n",
    "persona, query, response, cand = create_data(f\"./datasets/convai/train_self_original.txt\")\n",
    "for i in range(len(persona)):\n",
    "    for j in range(len(cand[i])):\n",
    "        train_dataset_chosen.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],response[i])))) + \"\\n\")\n",
    "        train_dataset_rejected.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],cand[i][j])))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691ef16-cfe3-4044-9812-61c46cca969d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dataset_chosen[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89a0ce-03aa-41ce-8cad-28cdeb7230f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dataset_rejected[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fec5c-a4f5-4519-b50b-d804e0450dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "percentage = 0.2\n",
    "\n",
    "random_list = random.sample(my_list, int(len(my_list) * percentage))\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245d92b-5d65-4ec5-953c-5d1f1e1203b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
