{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c10c8-88ee-4848-a623-6517f506e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_sft.py \\\n",
    "    --pretrain \"./checkpoint/llama_7B\" \\\n",
    "    --model 'llama' \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --log_interval 10 \\\n",
    "    --save_path \"./checkpoint_mine/step1/epoch1\" \\\n",
    "    --dataset 'PersonaChat' \\\n",
    "    --batch_size 2 \\\n",
    "    --accumulation_steps 8 \\\n",
    "    --lr 2e-5 \\\n",
    "    --max_epochs 1 \\\n",
    "    --max_datasets_size 1024 \\\n",
    "    --lora_rank 16 \\\n",
    "    --batch_size 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c3781-4e96-47fc-b749-1844b305e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_reward_model.py \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --model 'bloom' \\\n",
    "    --pretrain 'bigscience/bloom-560m' \\\n",
    "    --dataset 'PersonaChat' \\\n",
    "    --save_path './checkpoint_mine/step2/epoch1/rmstatic.pt' \\\n",
    "    --max_epochs 1 \\\n",
    "    --batch_size 8 \\\n",
    "    --loss_fn 'log_exp' \\\n",
    "    --max_datasets_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b75b1-2703-48b8-9836-68e2e292b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --standalone --nproc_per_node=1 train_prompts.py \\\n",
    "    --prompt_dataset 'PersonaChat' \\\n",
    "    --pretrain_dataset 'PersonaChat' \\\n",
    "    --strategy colossalai_zero2 \\\n",
    "    --model 'llama' \\\n",
    "    --pretrain './checkpoint_mine/step1/epoch1' \\\n",
    "    --rm_model 'bloom' \\\n",
    "    --rm_pretrain 'bigscience/bloom-560m' \\\n",
    "    --rm_path './checkpoint_mine/step2/epoch1/rmstatic.pt' \\\n",
    "    --save_path './checkpoint_mine/step3/epoch1' \\\n",
    "    --max_epochs 1 \\\n",
    "    --train_batch_size 1 \\\n",
    "    --ptx_batch_size 1 \\\n",
    "    --lora_rank 16 \\\n",
    "    --max_input_len 512 \\\n",
    "    --max_seq_len 512 \\\n",
    "    --max_datasets_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9faee46-66e7-4e6d-bf8b-b120a7d77869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#original\n",
    "{'input_ids': tensor([[    1,  1128,   508,   306, 11157,   590,  4700, 30010, 29879,   501,\n",
    "         29990,  2874, 29973,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0],\n",
    "        [    1,  6204,   263,  1051,   310,  5320,  5412,  9850, 15422,   800,\n",
    "           393,   526,   451,  5972,  6282,   391,   805,  1862, 29889,  9133,\n",
    "           680,   263, 11473,  6139,   363,  1269, 12551, 29892, 12141,   292,\n",
    "           825,  6166,   372, 12435,   515,   916,  5972,  9850, 14354, 29889,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "       device='cuda:0')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42d6813-6399-41f0-bf53-bea48c056a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prompt_dataset \u001b[38;5;241m=\u001b[39m PromptDataset(tokenizer\u001b[38;5;241m=\u001b[39m\u001b[43mtokenizer\u001b[49m, data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/prompts_en.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, max_datasets_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16384\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mis_initialized() \u001b[38;5;129;01mand\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mget_world_size() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m     prompt_sampler \u001b[38;5;241m=\u001b[39m DistributedSampler(prompt_dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path='datasets/prompts_en.jsonl', max_datasets_size=16384)\n",
    "if dist.is_initialized() and dist.get_world_size() > 1:\n",
    "    prompt_sampler = DistributedSampler(prompt_dataset, shuffle=True, seed=42, drop_last=True)\n",
    "else:\n",
    "    prompt_sampler = None\n",
    "prompt_dataloader = DataLoader(prompt_dataset,\n",
    "                               shuffle=(prompt_sampler is None),\n",
    "                               sampler=prompt_sampler,\n",
    "                               batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f0db31-dfed-4a6c-8c2b-9aa1dfc225c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {})\n",
      "defaultdict(<class 'list'>, {'p': [1, 2, 3], 'h': [1, 2, 3]})\n",
      "{'p': [1, 2, 3], 'h': [1, 2, 3]}\n",
      "<class 'collections.defaultdict'>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "result = defaultdict(list)\n",
    "print(result)\n",
    "data = [(\"p\", 1), (\"p\", 2), (\"p\", 3),\n",
    "        (\"h\", 1), (\"h\", 2), (\"h\", 3)]\n",
    "#print(type(result))\n",
    "#print(type(data))\n",
    "#print(data[:2])\n",
    "for (key, value) in data:\n",
    "    result[key].append(value)\n",
    "print(result)#defaultdict(<class 'list'>, {'p': [1, 2, 3], 'h': [1, 2, 3]})\n",
    "print(dict(result))\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b0598-e227-4450-a284-da65b150ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "        prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path='datasets/prompts_en.jsonl', max_datasets_size=16384)\n",
    "        if dist.is_initialized() and dist.get_world_size() > 1:\n",
    "            prompt_sampler = DistributedSampler(prompt_dataset, shuffle=True, seed=42, drop_last=True)\n",
    "        else:\n",
    "            prompt_sampler = None\n",
    "        prompt_dataloader = DataLoader(prompt_dataset,\n",
    "                                       shuffle=(prompt_sampler is None),\n",
    "                                       sampler=prompt_sampler,\n",
    "                                       batch_size=args.experience_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedef15f-e2c6-47e5-8cc8-6d8b253d4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traceback (most recent call last):\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 283, in <module>\n",
    "    main(args)\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 239, in main\n",
    "    trainer.fit(prompt_dataloader=prompt_dataloader,\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/coati/trainer/ppo.py\", line 151, in fit\n",
    "    experience = self._make_experience(prompts)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/coati/trainer/ppo.py\", line 100, in _make_experience\n",
    "    return self.experience_maker.make_experience(**inputs, **self.generate_kwargs)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/coati/experience_maker/naive.py\", line 19, in make_experience\n",
    "    sequences, attention_mask, action_mask = self.actor.generate(input_ids,\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/coati/models/base/actor.py\", line 48, in generate\n",
    "    action_mask = F.pad(action_mask, (1 + input_len, -1), value=True)    # include eos token and input\n",
    "RuntimeError: start (0) + length (-1) exceeds dimension size (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b10f3-0e33-4380-b860-330b5b6f8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, max_datasets_size: int = None, max_length: int = 512):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logger.info(\"Loading data...\")\n",
    "        list_data_dict = jload(data_path)\n",
    "        logger.info(f\"Loaded {len(list_data_dict)} examples.\")\n",
    "\n",
    "        if max_datasets_size is not None:\n",
    "            logger.info(f\"Limiting dataset to {max_datasets_size} examples.\")\n",
    "            list_data_dict = list_data_dict[:max_datasets_size]\n",
    "\n",
    "        logger.info(\"Formatting inputs...\")\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logger.info(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer, max_length)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ffbb1-fecb-4806-a51b-493a484c3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PersonaPromptProcess(data_file, max_datasets_size):\n",
    "    dataset_prompt = []\n",
    "    \n",
    "    persona, query, response, _ = create_data(data_file, max_datasets_size)\n",
    "\n",
    "    for i in range(len(persona)):\n",
    "        dialogue = []\n",
    "        dialogue.append(query[i][0])\n",
    "\n",
    "        dataset_prompt.append( \"\\n\".join(persona[i] + [query[i][0]] ))\n",
    "\n",
    "        for j in range(len(query[i])-1):\n",
    "            dialogue.append(response[i][j])\n",
    "            dialogue.append(query[i][j+1])\n",
    "\n",
    "            dataset_prompt.append( \"\\n\".join(persona[i] + dialogue ))\n",
    "\n",
    "    return dataset_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3fc05-1271-44f1-aa61-edf777cf7d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a94886-3eca-41ea-8b10-2d95390f6570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor\n",
    "print(keyed_prompt[1].extend(tensor.to(torch.cuda.current_device()).unbind())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706665b3-8383-4439-ad18-b094bd7b3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'instruction': 'I\\'m trying to solve a CTF challenge. The program looks like:\\nvoid print_flag()\\n{\\n    char flagbuf[256];\\n    int fd = open(\"flag.txt\", O_RDONLY);\\n    read(fd, flagbuf, 256);\\n    write(1, flagbuf, 256);\\n    close(fd);\\n}\\nint main()\\n{\\n    char buf[32];\\n    gets(buf);\\n    printf(\"Hi, %s\\\\n\", buf);\\n    return 0;\\n}\\nI know print_flag is at 0x12345678, and the program is running on 32-bit x86 Linux. What input should I give it?'}, {'instruction': 'What is there one of in every corner and two of in every room?'}]\n",
    "[tensor([    1,   306, 29915, 29885,  1811,   304,  4505,   263,   315,  8969,\n",
    "        18766, 29889,   450,  1824,  3430,   763, 29901,    13,  5405,  1596,\n",
    "        29918, 15581,   580,    13, 29912,    13,  1678,  1373,  7353,  9721,\n",
    "        29961, 29906, 29945, 29953,  1385,    13,  1678,   938,   285, 29881,\n",
    "          353,  1722,   703, 15581, 29889,  3945,   613,   438, 29918, 29934,\n",
    "        29928,  1164, 16786,   416,    13,  1678,  1303, 29898, 11512, 29892,\n",
    "         7353,  9721, 29892, 29871, 29906, 29945, 29953,   416,    13,  1678,\n",
    "         2436, 29898, 29896, 29892,  7353,  9721, 29892, 29871, 29906, 29945,\n",
    "        29953,   416,    13,  1678,  3802, 29898, 11512,   416,    13, 29913,\n",
    "           13,   524,  1667,   580,    13, 29912], device='cuda:0'), tensor([    1,  1724,   338,   727,   697,   310,   297,  1432, 11155,   322,\n",
    "         1023,   310,   297,  1432,  5716, 29973,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0], device='cuda:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b962cf97-4d30-44c6-a8e1-dfd85ea68ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "a = [\"a\",\"b\",\"c\"]\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e19525-15c4-4e10-aa29-7673f76e355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/hpcaitech/ColossalAI/issues/3192\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 266, in <module>\n",
    "    main(args)\n",
    "  File \"/home/jovyan/work/Chat/train_prompts.py\", line 79, in main\n",
    "    reward_model.load_state_dict(state_dict)\n",
    "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1671, in load_state_dict\n",
    "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
    "RuntimeError: Error(s) in loading state_dict for LlamaRM:\n",
    "        Unexpected key(s) in state_dict: \"model.layers.0.self_attn.q_proj.lora_A\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc557a0-88b4-4121-9b33-ac94651d5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "I have the same problems.\n",
    "I add the `strict=False` to `reward_model.load_state_dict(state_dict)` and `critic.load_state_dict(state_dict)` can solve the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87e017-1d4c-4509-84e3-df086d896713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = data.TensorDataset(torch.randn(10, 3), torch.randn(10, 1))\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "    print(f\"Batch {i}:\\n{x_batch}\\n{y_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903129f-b144-40d0-930b-904d46ef3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path: str,\n",
    "                 tokenizer: transformers.PreTrainedTokenizer,\n",
    "                 max_datasets_size: int = None,\n",
    "                 max_length: int = 96):\n",
    "        super(PromptDataset, self).__init__()\n",
    "        self.keyed_prompt = defaultdict(list)\n",
    "        logger.info(\"Loading data...\")\n",
    "        list_data_dict = jload(data_path)\n",
    "        logger.info(f\"Loaded {len(list_data_dict)} examples.\")\n",
    "\n",
    "        if max_datasets_size is not None:\n",
    "            logger.info(f\"Limiting dataset to {max_datasets_size} examples.\")\n",
    "            list_data_dict = list_data_dict[:max_datasets_size]\n",
    "\n",
    "        for data_dict in list_data_dict:\n",
    "            token = tokenizer(data_dict[\"instruction\"],\n",
    "                              return_tensors='pt',\n",
    "                              max_length=max_length,\n",
    "                              padding='max_length',\n",
    "                              truncation=True)\n",
    "            for k, tensor in token.items():\n",
    "                self.keyed_prompt[k].extend(tensor.to(torch.cuda.current_device()).unbind())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keyed_prompt[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return {k: v[i] for k, v in self.keyed_prompt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a0bf8-62f6-4fb2-a87a-542fa34aadaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataprocess import create_data\n",
    "inputs = []\n",
    "outputs = []\n",
    "persona, query, response, _ = create_data(\"./datasets/convai/train_self_original.txt\")\n",
    "print(query[0][:10])\n",
    "print(response[0][:10])\n",
    "for i in range(len(persona)):\n",
    "    dialogue = []\n",
    "    dialogue.append(query[i][0])\n",
    "    inputs.append(\"\\n\".join(persona[i]+[query[i][0]]))\n",
    "    outputs.append(response[i][0])\n",
    "    \n",
    "    for j in range(len(query[i])-1):\n",
    "        dialogue.append(response[i][j])\n",
    "        dialogue.append(query[i][j+1])\n",
    "        inputs.append(\"\\n\".join(persona[i] + dialogue))\n",
    "        outputs.append(response[i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae4a2c-6ca5-4380-961f-08c70a1b13f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for i in itertools.count(10,2):\n",
    "    print(i)\n",
    "    if i>20: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a6312-8853-44a3-9e34-68b08f28098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocess import create_data\n",
    "def PersonaPromptDataset(data_file, max_datasets_size):\n",
    "    dataset_chosen = []\n",
    "    dataset_rejected = []\n",
    "\n",
    "    persona, query, response, cand = create_data(data_file, max_datasets_size)\n",
    "    for i in range(len(persona)):\n",
    "        for j in range(len(persona[i])):\n",
    "            dataset_chosen.append(\"\\n\".join(persona[i][:j] + \n",
    "                                            list(itertools.chain.from_iterable(zip(query[i][:j],response[i][:j])))) + \"\\n\")\n",
    "            dataset_rejected.append(\"\\n\".join(persona[i][:j] + \n",
    "                                            list(itertools.chain.from_iterable(zip(query[i][:j],cand[i][:j][0])))) + \"\\n\")\n",
    "\n",
    "    return dataset_chosen, dataset_rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea92cecd-e002-4ff7-a192-539b9d6d2a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000 1000\n",
      "./datasets/convai/valid_self_original.txt has 1000 dialog and 7801 query\n"
     ]
    }
   ],
   "source": [
    "from dataprocess import HhRlhfDataset, PersonaPromptDataLoader, create_data, PersonaPromptDataset\n",
    "dataset_chosen, dataset_rejected = PersonaPromptDataset(\"./datasets/convai/valid_self_original.txt\", 999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354ed381-7601-431e-afeb-b819c2389183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m[i])\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(inputs[i])\n",
    "    print(\"-\"*25)\n",
    "    print(outputs[i])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628f86e-1f60-49d6-b56a-e8879b732b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3c15b-963f-4c3d-bc16-6d4b4ee5ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def create_data(data_file):\n",
    "    with open(data_file, \"r\", encoding=\"utf8\") as f:\n",
    "        persona =[]\n",
    "        query = []\n",
    "        response = []\n",
    "        cand = []\n",
    "        is_persona = False\n",
    "        tmp_persona = []\n",
    "        tmp_query = []\n",
    "        tmp_response = []\n",
    "        tmp_cand = []\n",
    "        first = True\n",
    "        cnt = 0\n",
    "        sum_u = 0\n",
    "        for line in f:\n",
    "            cnt += 1\n",
    "            line = line.strip()\n",
    "            if \"your persona: \" in line:\n",
    "                if not is_persona and not first:\n",
    "                    query.append(tmp_query)\n",
    "                    response.append(tmp_response)\n",
    "                    cand.append(tmp_cand)\n",
    "                    sum_u += len(tmp_query)\n",
    "                    tmp_query = []\n",
    "                    tmp_response = []\n",
    "                    tmp_cand = []\n",
    "                first = False\n",
    "                is_persona = True\n",
    "                line = line.split(\": \", maxsplit=1)[1]\n",
    "                tmp_persona.append(line)\n",
    "            else:\n",
    "                if is_persona:\n",
    "                    persona.append(tmp_persona)\n",
    "                    is_persona = False\n",
    "                    tmp_persona = []\n",
    "                line = line[line.find(\" \")+1:]\n",
    "                tmp_query.append(line.split(\"\\t\")[0])\n",
    "                tmp_response.append(line.split(\"\\t\")[1])\n",
    "                tmp_cand.append(line.split(\"\\t\")[3].split(\"|\"))\n",
    "        query.append(tmp_query)\n",
    "        response.append(tmp_response)\n",
    "        cand.append(tmp_cand)\n",
    "        sum_u += len(tmp_query)\n",
    "        assert len(query) == len(response) == len(persona) == len(cand)\n",
    "\n",
    "    print(\"{} has {} dialog and {} query\".format(data_file, len(query), sum_u))\n",
    "\n",
    "    return persona, query, response, cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb5b8a-111b-4c98-a011-e94d58bca8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_chosen = []\n",
    "train_dataset_rejected = []\n",
    "eval_dataset_chosen = []\n",
    "eval_dataset_rejected = []\n",
    "\n",
    "persona, query, response, cand = create_data(f\"./datasets/convai/valid_self_original.txt\")\n",
    "print(persona[:2])\n",
    "print()\n",
    "print(query[:2])\n",
    "print()\n",
    "print(cand[:2])\n",
    "\n",
    "for i in range(len(persona)):\n",
    "    for j in range(len(cand[i])):\n",
    "        eval_dataset_chosen.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],response[i])))) + \"\\n\")\n",
    "        eval_dataset_rejected.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],cand[i][j])))) + \"\\n\")\n",
    "train_dataset_chosen = []\n",
    "train_dataset_rejected = []\n",
    "eval_dataset_chosen = []\n",
    "eval_dataset_rejected = []\n",
    "\n",
    "persona, query, response, cand = create_data(f\"./datasets/convai/train_self_original.txt\")\n",
    "for i in range(len(persona)):\n",
    "    for j in range(len(cand[i])):\n",
    "        train_dataset_chosen.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],response[i])))) + \"\\n\")\n",
    "        train_dataset_rejected.append(\"\\n\".join(persona[i] + list(itertools.chain.from_iterable(zip(query[i],cand[i][j])))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691ef16-cfe3-4044-9812-61c46cca969d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dataset_chosen[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89a0ce-03aa-41ce-8cad-28cdeb7230f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval_dataset_rejected[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fec5c-a4f5-4519-b50b-d804e0450dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "percentage = 0.2\n",
    "\n",
    "random_list = random.sample(my_list, int(len(my_list) * percentage))\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245d92b-5d65-4ec5-953c-5d1f1e1203b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
